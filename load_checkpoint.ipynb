{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_size': 224, 'patch_size': 32, 'mode': 'base', 'embed_dim': 512}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take key state_dict in provided checkpoint dict\n",
      "Pretrained weights found at /shared/js.yun/DINO_sagemaker/ckpts/exp/epoch=48.ckpt and loaded with msg: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from vision_transformer3 import vision_transformer3 \n",
    "\n",
    "default_kwargs = {\n",
    "                            # image\n",
    "                        'image_size': 224,\n",
    "                        'patch_size': 32, # if '32' in hparams.arch else 16,\n",
    "                        'mode': 'base',\n",
    "                        'embed_dim': 512\n",
    "                    }\n",
    "print(default_kwargs)\n",
    "model=vision_transformer3(**default_kwargs)\n",
    "\n",
    "\n",
    "pretrained_weights = '/shared/js.yun/DINO_sagemaker/ckpts/exp/epoch=48.ckpt'\n",
    "state_dict = torch.load(pretrained_weights, map_location=\"cpu\")\n",
    "# checkpoint_key = 'teacher'\n",
    "checkpoint_key = 'state_dict'\n",
    "\n",
    "# for i in state_dict:\n",
    "#     print(i)\n",
    "\n",
    "if checkpoint_key is not None and checkpoint_key in state_dict:\n",
    "    print(f\"Take key {checkpoint_key} in provided checkpoint dict\")\n",
    "    state_dict = state_dict[checkpoint_key]\n",
    "    # print(state_dict)\n",
    "\n",
    "teacher_dict = {}\n",
    "for k,v in state_dict.items():\n",
    "    if 'teacher.backbone' in k:\n",
    "        key = k.replace(\"teacher.backbone.\", \"\")\n",
    "        teacher_dict[key] = v\n",
    "\n",
    "# remove `module.` prefix\n",
    "state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "# remove `backbone.` prefix induced by multicrop wrapper\n",
    "state_dict = {k.replace(\"backbone.\", \"\"): v for k, v in state_dict.items()}\n",
    "msg = model.load_state_dict(teacher_dict, strict=False)\n",
    "print('Pretrained weights found at {} and loaded with msg: {}'.format(pretrained_weights, msg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
